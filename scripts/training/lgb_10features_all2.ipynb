{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import copy\n",
    "import joblib\n",
    "from datetime import datetime, date, timedelta\n",
    "import random as rn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1234\n",
    "np.random.seed(seed)\n",
    "rn.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.read_csv('../../data/y_1/10features', sep='|', compression='bz2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train_setup import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_list = df_all['time_id'].unique().tolist()\n",
    "len(time_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train = list(set(time_list) - set(all_test))\n",
    "len(all_train), len(all_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k1_train = list(set(all_train)-set(k1_test))\n",
    "k2_train = list(set(all_train)-set(k2_test))\n",
    "k3_train = list(set(all_train)-set(k3_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(k1_train), len(k1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(k2_train), len(k2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(k3_train), len(k3_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_test), len(all_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rename_map = {}\n",
    "for i, col in enumerate(final_feats):\n",
    "    rename_map[col]=f'feat{i+1}'\n",
    "    \n",
    "df_all.rename(columns=rename_map, inplace=True)\n",
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold_list_ = [[df_all[df_all['time_id'].isin(k1_train)], df_all[df_all['time_id'].isin(k1_test)], ], \n",
    "              [df_all[df_all['time_id'].isin(k2_train)], df_all[df_all['time_id'].isin(k2_test)], ], \n",
    "              [df_all[df_all['time_id'].isin(k3_train)], df_all[df_all['time_id'].isin(k3_test)], ], \n",
    "             ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['feat1', 'feat2', 'feat3', 'feat4', 'feat5', 'feat6', 'feat7', 'feat8', 'feat9', 'feat10']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler=5\n",
    "kfold_list = []\n",
    "for df_train_, df_test_ in kfold_list_:\n",
    "    print(df_train_.shape, df_test_.shape)\n",
    "    df_train = df_train_.copy(deep=True)\n",
    "    df_test = df_test_.copy(deep=True)\n",
    "    \n",
    "    df_train.set_index(keys=['stock_id', 'time_id'], inplace=True)\n",
    "    df_test.set_index(keys=['stock_id', 'time_id'], inplace=True)\n",
    " \n",
    "\n",
    "    for i in range(1, len(final_feats)+1):\n",
    "        col=f'feat{i}'\n",
    "\n",
    "        avg = df_train[col].mean()\n",
    "        std = df_train[col].std()\n",
    "        df_train[df_train[col]>avg+scaler*std] = avg+scaler*std\n",
    "        df_train[df_train[col]<avg-scaler*std] = avg-scaler*std\n",
    "        df_test[df_test[col]>avg+scaler*std] = avg+scaler*std\n",
    "        df_test[df_test[col]<avg-scaler*std] = avg-scaler*std\n",
    "        \n",
    "        \n",
    "    X_train=df_train[features].copy(deep=True)\n",
    "    y_train = df_train[['target']].copy(deep=True)\n",
    "    y_train['target']=df_train_['target'].values\n",
    "    \n",
    "    X_test=df_test[features].copy(deep=True)\n",
    "    y_test=df_test[['target']].copy(deep=True)\n",
    "    y_test['target']=df_test_['target'].values\n",
    "    \n",
    "    kfold_list.append([X_train, y_train, X_test, y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del kfold_list_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hyperopt setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials, anneal, rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp\n",
    "import numpy as np\n",
    "\n",
    "search_space = { \n",
    "                 'num_boost_round': hp.choice('num_boost_round',list(range(300, 1201, 1))),\n",
    "                 'boosting':hp.choice('boosting', ['gbdt']),\n",
    "                 'objective':hp.choice('objective', ['regression_l2'] ),#,'regression_l1'\n",
    "                 'metric':hp.choice('metric', ['mae']),\n",
    "                 'max_leaves': hp.choice('max_leaves', range(30, 301, 5)),#int\n",
    "                 'learning_rate':  hp.choice('learning_rate', np.round(np.arange(0.01, 0.75, 0.01),3)), \n",
    "                 'feature_fraction': hp.choice('feature_fraction', np.round(np.arange(0.45, 0.86, 0.01),3)), \n",
    "                 #learning control parameters: https://lightgbm.readthedocs.io/en/latest/Parameters.html#metric-parameters\n",
    "                 'max_depth': hp.choice('max_depth', range(9, 24, 1)), #int type\n",
    "                 'min_data_in_leaf': hp.choice('min_data_in_leaf',range(30, 501, 1)), #int type\n",
    "                 'lambda_l1':hp.choice('lambda_l1', range(5, 15, 1)),#reg_alpha\n",
    "                 'lambda_l2':hp.choice('lambda_l2', range(5, 15, 1)),#reg_lambda\n",
    "                 'max_bin':hp.choice('max_bin', range(20, 350, 5)),#'max_bin':hp.quniform('max_bin', 100, 500, 50),#int\n",
    "                 'min_data_in_bin':hp.choice('min_data_in_bin', range(10, 100, 1)),\n",
    "                 #'min_split_gain':hp.choice('min_split_gain', np.round(np.arange(0.0005, 0.01, 0.0001),5)),\n",
    "                 'bagging_fraction':hp.choice('bagging_fraction', np.round(np.arange(0.5, 0.86, 0.01),3)), \n",
    "                 'bagging_freq':hp.choice('bagging_freq', range(20, 101, 1)),# int\n",
    "                 #'min_child_weight':hp.choice('min_child_weight', range(300, 1000, 5))# int\n",
    "                  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_lgb_preds(X_train, y_train,X_test, num_round=100, params={}, verbose=False):\n",
    "    \n",
    "    dtrain = lgb.Dataset(X_train, y_train)\n",
    "    tree_model = lgb.train(params,\n",
    "                dtrain,\n",
    "                num_boost_round=num_round,\n",
    "                verbose_eval=verbose)\n",
    "    \n",
    "    y_preds = tree_model.predict(X_test, num_iteration=tree_model.best_iteration)\n",
    "    scores = tree_model.feature_importance(importance_type='gain', iteration=tree_model.best_iteration)\n",
    "    df_scores = pd.DataFrame({'feature':list(X_train.columns), 'gain': list(scores)})\n",
    "\n",
    "    return y_preds, df_scores, tree_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "def score(params):\n",
    "   \n",
    "    num_boost_round = params['num_boost_round']\n",
    "    \n",
    "    if params in all_params:\n",
    "        return {'loss': 99999, 'status': STATUS_OK}\n",
    "    \n",
    "    all_params.append(copy.deepcopy(params))\n",
    "    \n",
    "    del params['num_boost_round']\n",
    "    params['verbose']=-1\n",
    "    \n",
    "    i = len(all_params)\n",
    "    pred_list = []\n",
    "    \n",
    "    for j, (X_train, y_train, X_test, y_test) in enumerate(kfold_list):\n",
    "        y_preds, df_scores, i_model = make_lgb_preds(X_train, y_train, X_test, params=params,\n",
    "                                                       num_round=num_boost_round,  verbose=False)\n",
    "        df_pred = y_test.copy(deep=True)\n",
    "        df_pred['pred'] = y_preds\n",
    "        df_pred['fold'] = j+1\n",
    "        pred_list.append(df_pred)\n",
    "        \n",
    "    df_pred_all = pd.concat(pred_list, axis=0)\n",
    "   \n",
    "    loss = mean_squared_error(df_pred_all['target'], df_pred_all['pred'])\n",
    "   \n",
    "    \n",
    "    item = [i, all_params[i-1],  -loss] \n",
    "    all_metrics.append(item)\n",
    "    df_pred_all.to_csv(save_dir.joinpath('kfold_'+str(i)), sep='|', index=True, compression='bz2')\n",
    "    \n",
    "    \n",
    "    i = i + 1\n",
    "    \n",
    "    if i%10==0:\n",
    "        save_metric(all_metrics, save_dir.parent, trial_folder+'.xlsx')\n",
    "        joblib.dump(trials, save_dir.parent.joinpath(trial_folder+'.pkl'))\n",
    "    \n",
    "    return {'loss': loss, 'status': STATUS_OK}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_metric(metric_list, trials_dir, file_name):\n",
    "    df_params = pd.DataFrame(data = metric_list, columns = ['trial_id', 'params',  'metric'])\n",
    "    df_params.index.name='row_nr'\n",
    "    df_params.to_excel(trials_dir.joinpath(file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "def optimize(space, evals, cores, trials, optimizer=tpe.suggest, random_state=1234, n_startup_jobs=50):\n",
    "    space['nthread']= cores\n",
    "    space['seed']= random_state\n",
    "    algo = partial(optimizer, n_startup_jobs=n_startup_jobs)\n",
    "    best = fmin(score, space, algo=algo, max_evals=evals, trials = trials)\n",
    "    print(best)\n",
    "    return best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_folder = '10features_all2'\n",
    "trials_dir = Path(f'../../trials')\n",
    "save_dir = Path(f'../../trials/{trial_folder}')\n",
    "save_dir.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_trials = 8000\n",
    "n_random_trials = 2500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cores = 4\n",
    "n=n_trials\n",
    "verbose = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metrics = []\n",
    "all_params = []\n",
    "trials = Trials()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_param = optimize(search_space,\n",
    "                      evals = n,\n",
    "                      optimizer=tpe.suggest,\n",
    "                      cores = cores,\n",
    "                      trials = trials, random_state=1234, \n",
    "                      n_startup_jobs=n_random_trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
